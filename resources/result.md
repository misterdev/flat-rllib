{
    'trainer': <ray.rllib.agents.trainer_template.PPO object at 0x7fbc44cbfda0>,
    'result': {
        'episode_reward_max': -127.0,
        'episode_reward_min': -441.0,
        'episode_reward_mean': -319.625,
        'episode_len_mean': 470.5,
        'episodes_this_iter': 4,
        'policy_reward_min': {},
        'policy_reward_max': {},
        'policy_reward_mean': {},
        'custom_metrics': {
            'score_mean': -159.8125,
            'score_min': -220.5,
            'score_max': -63.5,
            'proportion_episode_solved_mean': 1.0,
            'proportion_episode_solved_min': 1,
            'proportion_episode_solved_max': 1
        },
        'sampler_perf': {
            'mean_env_wait_ms': 3.3535228997060367,
            'mean_processing_ms': 1.0520746404101362,
            'mean_inference_ms': 0.9896701946959794
        },
        'off_policy_estimator': {},
        'info': {
            'num_steps_trained': 4224,
            'num_steps_sampled': 4339,
            'sample_time_ms': 8058.473,
            'load_time_ms': 79.442,
            'grad_time_ms': 3534.14,
            'update_time_ms': 709.601,
            'learner': {
                'default_policy': {
                    'cur_kl_coeff': 0.20000000298023224,
                    'cur_lr': 4.999999873689376e-05,
                    'total_loss': 409.21057,
                    'policy_loss': -0.018491542,
                    'vf_loss': 409.2256,
                    'vf_explained_var': 3.3429176e-05,
                    'kl': 0.017385451,
                    'entropy': 1.5922661,
                    'entropy_coeff': 0.0
                }
            }
        },
        'timesteps_this_iter': 4339,
        'done': False,
        'timesteps_total': 4339,
        'episodes_total': 4,
        'training_iteration': 1,
        'experiment_id': '2cf44cb65bc94295818846054036a7aa',
        'date': '2019-12-13_21-59-56',
        'timestamp': 1576270796,
        'time_this_iter_s': 12.451505661010742,
        'time_total_s': 12.451505661010742,
        'pid': 22878,
        'hostname': 'DEV-UBUNTU',
        'node_ip': '192.168.1.35',
        'config': {
            'monitor': False,
            'log_level': 'INFO',
            'callbacks': {
                'on_episode_start': <function on_episode_start at 0x7fbc62c0af28>,
                'on_episode_step': None,
                'on_episode_end': <function on_episode_end at 0x7fbb8b384048>,
                'on_sample_end': None,
                'on_train_result': <function on_train_result at 0x7fbb8b3847b8>,
                'on_postprocess_traj': None
            },
            'ignore_worker_failures': False,
            'log_sys_usage': True,
            'eager': False,
            'eager_tracing': False,
            'no_eager_on_workers': False,
            'model': {
                'conv_filters': None,
                'conv_activation': 'relu',
                'fcnet_activation': 'tanh',
                'fcnet_hiddens': [256, 256],
                'free_log_std': False,
                'no_final_linear': False,
                'vf_share_layers': True,
                'use_lstm': False,
                'max_seq_len': 20,
                'lstm_cell_size': 256,
                'lstm_use_prev_action_reward': False,
                'state_shape': None,
                'framestack': True,
                'dim': 84,
                'grayscale': False,
                'zero_mean': True,
                'custom_preprocessor': 'tree_obs_prep',
                'custom_model': None,
                'custom_action_dist': None,
                'custom_options': {}
            },
            'optimizer': {},
            'gamma': 0.99,
            'horizon': None,
            'soft_horizon': False,
            'no_done_at_end': False,
            'env_config': {},
            'env': 'FlatlandEnv',
            'clip_rewards': None,
            'clip_actions': True,
            'preprocessor_pref': 'deepmind',
            'lr': 5e-05,
            'evaluation_interval': None,
            'evaluation_num_episodes': 10,
            'evaluation_config': {},
            'num_workers': 2,
            'num_gpus': 0,
            'num_cpus_per_worker': 1,
            'num_gpus_per_worker': 0,
            'custom_resources_per_worker': {},
            'num_cpus_for_driver': 1,
            'memory': 0,
            'object_store_memory': 0,
            'memory_per_worker': 0,
            'object_store_memory_per_worker': 0,
            'num_envs_per_worker': 1,
            'sample_batch_size': 200,
            'train_batch_size': 4000,
            'batch_mode': 'truncate_episodes',
            'sample_async': False,
            'observation_filter': 'NoFilter',
            'synchronize_filters': True,
            'tf_session_args': {
                'intra_op_parallelism_threads': 2,
                'inter_op_parallelism_threads': 2,
                'gpu_options': {'allow_growth': True},
                'log_device_placement': False,
                'device_count': {'CPU': 1},
                'allow_soft_placement': True
            },
            'local_tf_session_args': {
                'intra_op_parallelism_threads': 8,
                'inter_op_parallelism_threads': 8
            },
            'compress_observations': False,
            'collect_metrics_timeout': 180,
            'metrics_smoothing_episodes': 100,
            'remote_worker_envs': False,
            'remote_env_batch_wait_ms': 0,
            'min_iter_time_s': 0,
            'timesteps_per_iteration': 0,
            'seed': None,
            'input': 'sampler',
            'input_evaluation': ['is', 'wis'],
            'postprocess_inputs': False,
            'shuffle_buffer_size': 0,
            'output': None,
            'output_compress_columns': ['obs', 'new_obs'],
            'output_max_file_size': 67108864,
            'multiagent': {'policies': {},
            'policy_mapping_fn': None,
            'policies_to_train': None},
            'use_gae': True,
            'lambda': 1.0,
            'kl_coeff': 0.2,
            'sgd_minibatch_size': 128,
            'shuffle_sequences': True,
            'num_sgd_iter': 30,
            'lr_schedule': None,
            'vf_share_layers': False,
            'vf_loss_coeff': 1.0,
            'entropy_coeff': 0.0,
            'entropy_coeff_schedule': None,
            'clip_param': 0.3,
            'vf_clip_param': 10.0,
            'grad_clip': None,
            'kl_target': 0.01,
            'simple_optimizer': False
        },
        'time_since_restore': 12.451505661010742,
        'timesteps_since_restore': 4339,
        'iterations_since_restore': 1
    }
}